#+TITLE: 732A61 \\ \large Lab 1
#+AUTHOR: Rasmus Holm
#+OPTIONS: toc:true
#+LaTeX_CLASS: article
#+LaTeX_CLASS_OPTIONS: [10pt]
#+LATEX_HEADER: \usepackage[font={scriptsize, it}]{caption}

\newpage

* \textit{k}-Means
In this exercise I have used the default options for the \textit{k}-means algorithm unless specified otherwise.

I have decided to use two settings, 2 and 5 clusters, and done two different cluster analysis. I have excluded
the name attribute since it is just a string and it is not possible to calculate distances based on arbitrary string
values.

** Result 1
In the first clustering I decided the use the features: Energy, Protein, Fat.
The decision was based on the scatterplot matrix where I could see that there seemed to be positive correlations between protein/fat and energy.

*** 2 Clusters
The resulting clusters can be seen below.

#+CAPTION: X-axis: Energy, Y-axis: Protein
#+ATTR_LATEX: :placement [H] :width 0.5\textwidth
[[./images/cl2_res1_01.png]]

#+CAPTION: X-axis: Energy Y-axis: Fat
#+ATTR_LATEX: :placement [H] :width 0.5\textwidth
[[./images/cl2_res1_02.png]]

We can see from the plots that the clusters seem good and are well separated.
The observations in the blue cluster have greater values in energy and fat with kind of an average value in protein.
We could say that the blue cluster contains energy rich and healthy food that are good when working out
while the red cluster contains food that are low-fat and low-energy that are good for weight loss.

*** 5 Clusters
The resulting clusters can be seen below.

#+CAPTION: X-axis: Energy, Y-axis: Protein
#+ATTR_LATEX: :placement [H] :width 0.5\textwidth
[[./images/cl5_res1_01.png]]

The clusters seem reasonable except that the green and the bright blue clusters in the middle are not as well defined as they could be.
The two green observations close to the blue cluster could be considered part of the blue cluster and I think that would have been better cluster assignments.

#+CAPTION: X-axis: Energy, Y-axis: Fat
#+ATTR_LATEX: :placement [H] :width 0.5\textwidth
[[./images/cl5_res1_02.png]]

However, this plot shows that the clusters are not as well defined as they first seemed. We can see that the green, red, and bright blue clusters overlap.
Overall, I would say that it is more appropriate to use 2 clusters than 5 using these attributes.

\newpage

** Result 2
Here I decided the use the remaining features: iron and calcium.

*** 2 Clusters
#+CAPTION: X-axis: Calcium, Y-axis: Iron
#+ATTR_LATEX: :placement [H] :width 0.5\textwidth
[[./images/cl2_res2_01.png]]

The clusters are not as well separated in this case since the observations are more scattared. It looks like it is suitable to find more than 2 clusters in this case.

*** 5 Clusters
#+CAPTION: X-axis: Calcium, Y-axis: Iron
#+ATTR_LATEX: :placement [H] :width 0.5\textwidth
[[./images/cl5_res2_01.png]]

Using 5 clusters yield much better clusters with higher separation and lower intra-cluster distances.
The within cluster sum of squared errors for 2 clusters was 2.13 and for 5 clusters it was 0.20 so we can see that it has
been reduced by 10 times.

** Seed
Since I am using random initialization the seed controls where the centroids are initialized which greatly influence what the final clusters will look like.

\newpage
* Density
I will be using the data I worked with in result 1 above and use 2 clusters
but this time turning $k$-means into a density-based clustering algorithm.

The MakeDensityBasedClusters class will create Gaussian distributions at the cluster centroids produced by the
$k$-means algorithm, i.e. the mean of the distributions are the cluster centroids, and the standard deviation (std) is
given by the observations assigned to each cluster. However, we can control the distributions by specifying
the minimum std which can widthen the distributions. The densities can then be used to calculate probabilities
for each observation being in each clusters which is also influenced by the prior probabilities, the ratio of points
in each cluster produced by $k$-means, and an observation is assigned to the cluster with highest probability.

Below are results with different minimum standard deviations.

#+CAPTION: X-axis: Energy, Y-axis: Protein
#+ATTR_LATEX: :placement [H] :width 0.5\textwidth
[[./images/cl2_res3_01.png]]

In the above plot I have used min std = 0.1 and we can see that the clusters are exactly the same as result from
the previous assignment using the regular $k$-means algorithm.

#+CAPTION: X-axis: Energy, Y-axis: Protein
#+ATTR_LATEX: :placement [H] :width 0.5\textwidth
[[./images/cl2_res3_02.png]]

Given min std = 100 we can see changes in the clusters and as expected the red cluster with more observations,
higher prior probability, consumes observations from the blue cluster.

#+CAPTION: X-axis: Energy, Y-axis: Protein
#+ATTR_LATEX: :placement [H] :width 0.5\textwidth
[[./images/cl2_res3_03.png]]

Similarly as previously, min std = 200 means the red cluster consumes even more points from the blue cluster.
